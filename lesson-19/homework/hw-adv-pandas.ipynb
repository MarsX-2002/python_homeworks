{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Merging and Joining**\n",
    "1. **Inner Join on Chinook Database**\n",
    "   - Load the `chinook.db` database.\n",
    "   - Perform an inner join between the `customers` and `invoices` tables on the `CustomerId` column.\n",
    "   - Find the total number of invoices for each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerId  Total_Invoices\n",
      "0           1               7\n",
      "1           2               7\n",
      "2           3               7\n",
      "3           4               7\n",
      "4           5               7\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the Chinook database\n",
    "conn = sqlite3.connect(r\"data\\chinook.db\")\n",
    "\n",
    "# Load tables into DataFrames\n",
    "customers = pd.read_sql_query(\"SELECT * FROM customers\", conn)\n",
    "invoices = pd.read_sql_query(\"SELECT * FROM invoices\", conn)\n",
    "\n",
    "# Perform inner join\n",
    "merged_df = customers.merge(invoices, on=\"CustomerId\", how=\"inner\")\n",
    "\n",
    "# Count the number of invoices per customer\n",
    "invoice_counts = merged_df.groupby(\"CustomerId\")[\"InvoiceId\"].count().reset_index()\n",
    "\n",
    "# Rename columns\n",
    "invoice_counts.columns = [\"CustomerId\", \"Total_Invoices\"]\n",
    "\n",
    "print(invoice_counts.head())\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Outer Join on Movie Data**\n",
    "   - Load the `movie.csv` file.\n",
    "   - Create two smaller DataFrames:\n",
    "     - One with only `director_name` and `color`.\n",
    "     - Another with `director_name` and `num_critic_for_reviews`.\n",
    "   - Perform a left join and then a full outer join on `director_name`.\n",
    "   - Count how many rows are in the resulting DataFrames for each join type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Join Rows: 5547\n",
      "Full Outer Join Rows: 5547\n"
     ]
    }
   ],
   "source": [
    "# Load movie dataset\n",
    "movies = pd.read_csv(r\"data/movie.csv\")\n",
    "\n",
    "# Create two smaller DataFrames\n",
    "df1 = movies[[\"director_name\", \"color\"]].drop_duplicates()\n",
    "df2 = movies[[\"director_name\", \"num_critic_for_reviews\"]].drop_duplicates()\n",
    "\n",
    "# Left join\n",
    "left_join_df = df1.merge(df2, on=\"director_name\", how=\"left\")\n",
    "\n",
    "# Full outer join\n",
    "full_outer_join_df = df1.merge(df2, on=\"director_name\", how=\"outer\")\n",
    "\n",
    "# Row counts\n",
    "print(f\"Left Join Rows: {len(left_join_df)}\")\n",
    "print(f\"Full Outer Join Rows: {len(full_outer_join_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Grouping and Aggregating**\n",
    "1. **Grouped Aggregations on Titanic**\n",
    "   - Group passengers by `Pclass` and calculate the following:\n",
    "     - Average age.\n",
    "     - Total fare.\n",
    "     - Count of passengers.\n",
    "   - Save the results to a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass    Avg_Age  Total_Fare  Passenger_Count\n",
      "0       1  38.233441  18177.4125              216\n",
      "1       2  29.877630   3801.8417              184\n",
      "2       3  25.140620   6714.6951              491\n"
     ]
    }
   ],
   "source": [
    "# Load Titanic dataset\n",
    "titanic = pd.read_excel(r\"data\\titanic.xlsx\")\n",
    "\n",
    "# Group by Pclass and aggregate\n",
    "grouped_titanic = titanic.groupby(\"Pclass\").agg(\n",
    "    Avg_Age=(\"Age\", \"mean\"),\n",
    "    Total_Fare=(\"Fare\", \"sum\"),\n",
    "    Passenger_Count=(\"PassengerId\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "print(grouped_titanic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Multi-level Grouping on Movie Data**\n",
    "   - Group the movies by `color` and `director_name`.\n",
    "   - Find:\n",
    "     - Total `num_critic_for_reviews` for each group.\n",
    "     - Average `duration` for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             color     director_name  Total_Critic_Reviews  Avg_Duration\n",
      "0  Black and White    Akira Kurosawa                 153.0         202.0\n",
      "1  Black and White    Aleksey German                 121.0         177.0\n",
      "2  Black and White      Alex Garland                 489.0         108.0\n",
      "3  Black and White   Alexander Payne                 433.0         115.0\n",
      "4  Black and White  Alfred Hitchcock                 434.0         119.0\n"
     ]
    }
   ],
   "source": [
    "# Group by color and director_name\n",
    "grouped_movies = movies.groupby([\"color\", \"director_name\"]).agg(\n",
    "    Total_Critic_Reviews=(\"num_critic_for_reviews\", \"sum\"),\n",
    "    Avg_Duration=(\"duration\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "print(grouped_movies.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Nested Grouping on Flights**\n",
    "   - Group flights by `Year` and `Month` and calculate:\n",
    "     - Total number of flights.\n",
    "     - Average arrival delay (`ArrDelay`).\n",
    "     - Maximum departure delay (`DepDelay`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year Month  Total_Flights  Avg_Arrival_Delay  Max_Departure_Delay\n",
      "0  2022     1         537902           3.981085               2512.0\n",
      "1  2022    10         572287           2.085886               2963.0\n",
      "2  2022    11         546410           4.708015               3433.0\n",
      "3  2022    12         557095          13.767535               3169.0\n",
      "4  2022     2         495713           4.674906               2545.0\n"
     ]
    }
   ],
   "source": [
    "# Load flights dataset\n",
    "flights = pd.read_parquet(r\"data\\flights\")\n",
    "\n",
    "# convert object dtype to numeric \n",
    "flights[\"ArrDelay\"] = pd.to_numeric(flights[\"ArrDelay\"], errors=\"coerce\")\n",
    "flights[\"DepDelay\"] = pd.to_numeric(flights[\"DepDelay\"], errors=\"coerce\")\n",
    "\n",
    "# Group by Year and Month\n",
    "grouped_flights = flights.groupby([\"Year\", \"Month\"]).agg(\n",
    "    Total_Flights=(\"FlightDate\", \"count\"),\n",
    "    Avg_Arrival_Delay=(\"ArrDelay\", \"mean\"),\n",
    "    Max_Departure_Delay=(\"DepDelay\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "print(grouped_flights.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Applying Functions**\n",
    "1. **Apply a Custom Function on Titanic**\n",
    "   - Write a function to classify passengers as `Child` (age < 18) or `Adult`.\n",
    "   - Use `apply` to create a new column, `Age_Group`, with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age Age_Group\n",
      "0  22.0     Adult\n",
      "1  38.0     Adult\n",
      "2  26.0     Adult\n",
      "3  35.0     Adult\n",
      "4  35.0     Adult\n"
     ]
    }
   ],
   "source": [
    "# Function to classify age group\n",
    "def classify_age(age):\n",
    "    return \"Child\" if age < 18 else \"Adult\"\n",
    "\n",
    "# Apply function\n",
    "titanic[\"Age_Group\"] = titanic[\"Age\"].apply(classify_age)\n",
    "\n",
    "print(titanic[[\"Age\", \"Age_Group\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Normalize Salaries in Chinook**\n",
    "   - Load the `chinook.db` database.\n",
    "   - Extract the `employees` table and normalize the salaries (`ReportsTo` column) within each department using `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeId  ReportsTo  Salary  Normalized_Salary\n",
      "0           1        NaN   65795                NaN\n",
      "1           2        1.0   50860          -0.707107\n",
      "2           3        2.0  104886           0.898222\n",
      "3           4        2.0   56265          -1.077520\n",
      "4           5        2.0   87194           0.179298\n",
      "5           6        1.0   94131           0.707107\n",
      "6           7        6.0  110263           0.707107\n",
      "7           8        6.0   66023          -0.707107\n"
     ]
    }
   ],
   "source": [
    "# Load the database\n",
    "conn = sqlite3.connect(\"data/chinook.db\")\n",
    "\n",
    "# Extract the employees table\n",
    "employees = pd.read_sql_query(\"SELECT * FROM employees\", conn)\n",
    "\n",
    "# Manually assign random salary values (for demonstration)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "employees[\"Salary\"] = np.random.randint(50000, 120000, size=len(employees))\n",
    "\n",
    "# Normalize salaries within each manager (ReportsTo)\n",
    "employees[\"Normalized_Salary\"] = employees.groupby(\"ReportsTo\")[\"Salary\"].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Display relevant columns\n",
    "print(employees[[\"EmployeeId\", \"ReportsTo\", \"Salary\", \"Normalized_Salary\"]])\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Custom Function on Movies**\n",
    "   - Write a function that returns `Short`, `Medium`, or `Long` based on the duration of a movie:\n",
    "     - `Short`: Less than 60 minutes.\n",
    "     - `Medium`: Between 60 and 120 minutes.\n",
    "     - `Long`: More than 120 minutes.\n",
    "   - Apply this function to classify movies in the `movie.csv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration Duration_Category\n",
      "0     178.0              Long\n",
      "1     169.0              Long\n",
      "2     148.0              Long\n",
      "3     164.0              Long\n",
      "4       NaN              Long\n"
     ]
    }
   ],
   "source": [
    "# Function to categorize movies by duration\n",
    "def categorize_duration(duration):\n",
    "    if duration < 60:\n",
    "        return \"Short\"\n",
    "    elif 60 <= duration <= 120:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Long\"\n",
    "\n",
    "# Apply function\n",
    "movies[\"Duration_Category\"] = movies[\"duration\"].apply(categorize_duration)\n",
    "\n",
    "print(movies[[\"duration\", \"Duration_Category\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Using `pipe`**\n",
    "1. **Pipeline on Titanic**\n",
    "   - Create a pipeline to:\n",
    "     - Filter passengers who survived (`Survived == 1`).\n",
    "     - Fill missing `Age` values with the mean.\n",
    "     - Create a new column, `Fare_Per_Age`, by dividing `Fare` by `Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked Age_Group  Fare_Per_Age  \n",
      "1      0          PC 17599  71.2833   C85        C     Adult      1.875876  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S     Adult      0.304808  \n",
      "3      0            113803  53.1000  C123        S     Adult      1.517143  \n",
      "8      2            347742  11.1333   NaN        S     Adult      0.412344  \n",
      "9      0            237736  30.0708   NaN        C     Child      2.147914  \n"
     ]
    }
   ],
   "source": [
    "def filter_survivors(df):\n",
    "    return df[df[\"Survived\"] == 1]  # Keeps only survivors\n",
    "\n",
    "def fill_missing_age(df):\n",
    "    df = df.copy()  # Avoids modifying a slice\n",
    "    df.loc[:, \"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "    return df  \n",
    "\n",
    "def add_fare_per_age(df):\n",
    "    df = df.copy()  # Avoids modifying a slice\n",
    "    df.loc[:, \"Fare_Per_Age\"] = df[\"Fare\"] / df[\"Age\"]\n",
    "    return df  \n",
    "\n",
    "# Load Titanic dataset (assuming `titanic` is already a DataFrame)\n",
    "titanic_processed = (titanic.pipe(filter_survivors)\n",
    "                              .pipe(fill_missing_age)\n",
    "                              .pipe(add_fare_per_age))\n",
    "\n",
    "print(titanic_processed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Pipeline on Flights**\n",
    "   - Create a pipeline to:\n",
    "     - Filter flights with a departure delay greater than 30 minutes.\n",
    "     - Add a column `Delay_Per_Hour` by dividing the delay by the scheduled flight duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DepDelayMinutes AirTime Delay_Per_Hour\n",
      "11             34.0    67.0       0.507463\n",
      "32             48.0    36.0       1.333333\n",
      "33             34.0    36.0       0.944444\n",
      "37             56.0    33.0        1.69697\n",
      "44             67.0    35.0       1.914286\n"
     ]
    }
   ],
   "source": [
    "def filter_delayed_flights(df):\n",
    "    \"\"\"Filter flights with a departure delay greater than 30 minutes.\"\"\"\n",
    "    # Convert 'DepDelayMinutes' to numeric and handle errors by coercing to NaN\n",
    "    df[\"DepDelayMinutes\"] = pd.to_numeric(df[\"DepDelayMinutes\"], errors='coerce')\n",
    "    return df[df[\"DepDelayMinutes\"] > 30].copy()  # Make a copy\n",
    "\n",
    "def add_delay_per_hour(df):\n",
    "    \"\"\"Add Delay_Per_Hour column.\"\"\"\n",
    "    # Ensure 'AirTime' is numeric and make a copy\n",
    "    df.loc[:, \"AirTime\"] = pd.to_numeric(df[\"AirTime\"], errors='coerce')\n",
    "    df.loc[:, \"Delay_Per_Hour\"] = df[\"DepDelayMinutes\"] / df[\"AirTime\"]\n",
    "    return df.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "\n",
    "# Apply the pipeline\n",
    "flights_processed = (flights.pipe(filter_delayed_flights)\n",
    "                             .pipe(add_delay_per_hour))\n",
    "\n",
    "# Display results\n",
    "print(flights_processed[[\"DepDelayMinutes\", \"AirTime\", \"Delay_Per_Hour\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
